{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A prototyping notebook for quickly testing and troubleshooting new functions or issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import src.api_call as ac\n",
    "import pandas as pd\n",
    "import src.text_process as tp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import src.bert_model as bm\n",
    "import src.model_evaluation as me\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to true if testing API code\n",
    "testing_api = False\n",
    "if testing_api:\n",
    "    ''' include API test code'''\n",
    "\n",
    "else:\n",
    "    # Default to locally saved text data\n",
    "    print ('Using local test files')\n",
    "    test_set = {\n",
    "    'Blockchain':0,\n",
    "    'Cryptocurrency':1, \n",
    "    'Genetic engineering':2, \n",
    "    'Machine learning':3, \n",
    "    'Nanotechnology':4, \n",
    "    'Quantum computing':5, \n",
    "    'Robotics':6, \n",
    "    'Social engineering':7, \n",
    "    'Space exploration':8, \n",
    "    'Virtual reality':9\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to true if testing text processing\n",
    "testing_text_process = False\n",
    "\n",
    "all_text = pd.DataFrame()\n",
    "\n",
    "if testing_text_process:\n",
    "    '''\n",
    "    text processing tests here\n",
    "    '''\n",
    "else:\n",
    "    # Default to text processing used in main\n",
    "    for key, value in test_set.items():\n",
    "        data = pd.DataFrame(pd.read_csv(f'raw_data/{str(key)}.csv'))\n",
    "        data = tp.english_papers(data, 'English')\n",
    "        data = tp.remove_hyperlinks(data)\n",
    "    \n",
    "        # tokenize text into sentences and convert to dataframe\n",
    "        data = pd.DataFrame(tp.text_clean(data['fullText']))\n",
    "    \n",
    "        # add column for encoding\n",
    "        data['Code'] = value\n",
    "\n",
    "        # rename columns\n",
    "        data.rename(columns = {0:'Text'}, inplace=True)\n",
    "\n",
    "        # append to final dataframe\n",
    "        all_text = all_text.append(data, ignore_index = True)\n",
    "    all_text.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_model = False\n",
    "\n",
    "if testing_model:\n",
    "    '''\n",
    "    model tests here\n",
    "    '''\n",
    "else:\n",
    "    # Default to model structure/functions used in main\n",
    "    x_train,x_test,y_train,y_test = train_test_split(all_text['Text'],all_text['Code'])\n",
    "\n",
    "    #generate a model\n",
    "    model = bm.generate_model(len(test_set))\n",
    "\n",
    "    #train model\n",
    "    model_history, train_time, eval = bm.compile_fit_evaluate(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_evaluation = False\n",
    "\n",
    "if testing_evaluation:\n",
    "    '''\n",
    "    evaluation tests here\n",
    "    '''\n",
    "else:\n",
    "    # Default to evaluation used in main\n",
    "    \n",
    "    #generate confusion matrix, save to local file\n",
    "    me.confusion_matrix(model, x_test, y_test, model_name)\n",
    "\n",
    "    # save text and model information\n",
    "    me.save_model_data(model,eval,model_history,model_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df4149841e132ab13f2b393b64f0f6daa407b0752c34bc27481ac15770fb4f14"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('textML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
